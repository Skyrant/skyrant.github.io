rh._.exports({"0":[["Job 'AggrPoller'"]],"1":[["\n"],["\n"],["\n","Dieser Job durchsucht die Datenbank nach fälligen Aggregationen \n und plant diese zum Ablauf ein. Diese Aggregationen können im LC2 unter \n \"Application Structure Settings – Data Exchange – Variables – Compression/Aggregation\" \n parametriert werden.","\n","Parametriert werden können die folgenden Aggregationszeiträume: \n Stunde, Tag, Woche, Monat und Jahr bzw. Schicht und Produktionstag. Außerdem \n ein beliebiges festes Zeitintervall mit Angabe der Minuten. ","\n","Während der Aggregation wird ermittelt, ob die angeforderte \n Aggregation auf Basis einer schon existierenden Aggregation berechnet \n werden kann. Zum Beispiel für Tagesaggregation können Stundenaggregationen \n als Vorberechnungen verwendet werden. Wurde keine Stundenaggregation definiert, \n so wird die Tagesaggregation auf Basis von Rohdaten berechnet.","\n","Die Ergebnisse dieser Aggregationen werden in der Tabelle \n P_VALUE_COMP_ARCHIVE gespeichert.","\n","Falls das Gateway gestoppt wurde und bereits Werte \n in p_value_archive für bereits berechnete Zeiträume existieren, werden \n diese nachaggregiert. Dies erfolgt mit einem Versatz nach dem Neustart \n des Gateways.","\n",":","\n","Die folgenden Spezialfälle sind in der aktuellen \n Version nicht umgesetzt:","\n","1. Handelt es sich bei dem Wert um den ersten \n Wert im berechneten Zeitraum und wurde die Aggregation mit einem der Interpolierungs-Typen \n \"after\" oder \"interpolate\" definiert, dann müssen \n alle Aggregationen dieser Definition von früheren Zeiträumen nachberechnet \n werden.","\n","2. Handelt es sich bei dem Wert um den letzten \n Wert im berechneten Zeitraum und wurde die Aggregation mit einem der Interpolierungs-Typen \n \"before\" oder \"interpolate\" definiert, dann müssen \n alle Aggregationen dieser Definition von früheren Zeiträumen nachberechnet \n werden.","\n","Der Einsatz des Jobs ist unabhängig vom Einsatz eines \n bestimmten Legato-Moduls.","\n","Log-Ausgaben dieses Jobs erfolgen in das Log-File der \n jeweiligen SE-Instanz unter dem Namen 'AggrPoller'. Um die Ausführlichkeit \n der Log-Ausgaben getrennt von der anderer Jobs einzustellen, ist eine \n Zeile mit Inhalt \"logger.de.gefasoft.legato.sapient.sapieng.jobs.compressedval.AggrPoller \n = <loglevel>\" in die Logging-Konfiguration einzutragen.","\n","Laufende Aggregationen schreiben Log-Ausgaben in das \n Log-File der jeweiligen SE-Instanz unter dem Namen 'Aggregator'. Um die \n Ausführlichkeit der Log-Ausgaben getrennt von der anderer Jobs einzustellen, \n ist eine Zeile mit Inhalt \"logger.de.gefasoft.legato.sapient.sapieng.jobs.compressedval.AggrPoller \n = <loglevel>\" in die Logging-Konfiguration einzutragen.","\n"],["\n","\n\t","\n\t","\n\t","\n\t\t","Symbol:","\n\t\t","AGGR_POLLER","\n\t","\n\t","\n\t\t","Name:","\n\t\t","AggrPoller","\n\t","\n\t","\n\t\t","Modul:","\n\t\t","n/a","\n\t","\n\t","\n\t\t","SE-Instanz:","\n\t\t","Nummer \n\t\t der Sapient Engine Instanz. ","\n\t","\n\t","\n\t\t","Scheduler:","\n\t\t","main","\n\t","\n\t","\n\t\t","Funktions-Pfad:","\n\t\t","/de/gefasoft/sapient/sapieng/jobs/compressedval/AggrPoller/execute","\n\t","\n\t","\n\t\t","Parameter \n\t\t (JSON):","\n\t\t","{","\n\t\t","\"queue\": 25,","\n\t\t","\"maxPerRun\": 10000","\n\t\t","}","\n\t","\n\t","\n\t\t","Timeout \n\t\t (s) (optional):","\n\t\t","n/a","\n\t","\n","\n"," ","\n"],["\n","queue","\n","Limitiert die Größe der Abarbeitungs-Queue, die die \n Aggregations-Bearbeitungs-Threads beliefert. Defaultwert ist 25 Einträge \n pro Aggregations-Thread.","\n","maxPerRun","\n","Limitiert die Anzahl der Aggregationen, die pro Jobausführung \n bearbeitet werden. Defaultwert ist 10000.","\n"],["\n","Standard-Trigger: zyklisch (-1)","\n","Standard-Intervall: {\"Interval\": \"1m\"}","\n\n\n"]],"2":[["Job 'AggrPoller'"]],"5":[["Aggregation"]],"6":[["Beschreibung"],["Parametrierung"],["Bedeutung der Parameter"],["Trigger"]],"id":"57"})